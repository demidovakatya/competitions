{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/jeffd23/leaf-classification/10-classifier-showdown-in-scikit-learn/code\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3bb42045-03bc-0ca3-36c9-9379444c88b1"
   },
   "source": [
    "# Which Classifier is Should I Choose? \n",
    "\n",
    "This is one of the most import questions to ask when approaching a machine learning problem. I find it easier to just test them all at once. Here's 10 of your favorite Scikit-Learn algorithms applied to the leaf data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "e86aec01-dbc6-4696-e066-6da72fedd092",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def warn(*args, **kwargs): pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5de1ab5b-9b22-2375-4705-f6d12e9d3046"
   },
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "361c2695-95c0-745a-0336-a49f6dec97b2",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "0  0.007812  0.023438  0.023438  0.003906  0.011719  0.009766  0.027344   \n",
       "\n",
       "   margin8   margin9  margin10    ...      texture55  texture56  texture57  \\\n",
       "0      0.0  0.001953  0.033203    ...       0.007812        0.0    0.00293   \n",
       "\n",
       "   texture58  texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0    0.00293   0.035156        0.0        0.0   0.004883        0.0   0.025391  \n",
       "\n",
       "[1 rows x 192 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swiss army knife function to organize the data\n",
    "\n",
    "def encode(train, test):\n",
    "    le = LabelEncoder().fit(train.species) \n",
    "    labels = le.transform(train.species)           # encode species strings\n",
    "    classes = list(le.classes_)                    # save column names for submission\n",
    "    test_ids = test.id                             # save test ids for submission\n",
    "    \n",
    "    train = train.drop(['species', 'id'], axis=1)  \n",
    "    test = test.drop(['id'], axis=1)\n",
    "    \n",
    "    return train, labels, test, test_ids, classes\n",
    "\n",
    "train, labels, test, test_ids, classes = encode(train, test)\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3222a1a2-6df6-e5a6-2c4d-65383fc9ee66"
   },
   "source": [
    "## Stratified Train/Test Split\n",
    "\n",
    "Stratification is necessary for this dataset because there is a relatively large number of classes (100 classes for 990 samples). This will ensure we have all classes represented in both the train and test indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "7c91b9c9-3b4d-73ac-92d8-db0792f60a3e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n",
    "\n",
    "for train_index, test_index in sss:\n",
    "    X_train, X_test = train.values[train_index], train.values[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1172a79-cdc8-6544-2580-4a58ee9fb434"
   },
   "source": [
    "## Sklearn Classifier Showdown\n",
    "\n",
    "Simply looping through 10 out-of-the box classifiers and printing the results. Obviously, these will perform much better after tuning their hyperparameters, but this gives you a decent ballpark idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "fb7913b9-e36d-ef8b-a012-cc708b583ab4",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Accuracy: 88.8889%\n",
      "Log Loss: 1.5755075129933762\n",
      "==============================\n",
      "SVC\n",
      "****Results****\n",
      "Accuracy: 81.8182%\n",
      "Log Loss: 4.606698203326236\n",
      "==============================\n",
      "NuSVC\n",
      "****Results****\n",
      "Accuracy: 88.3838%\n",
      "Log Loss: 2.495700876274709\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 64.6465%\n",
      "Log Loss: 12.210678523453367\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 84.3434%\n",
      "Log Loss: 1.2245537766961432\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 4.5455%\n",
      "Log Loss: 4.202877746190806\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 57.5758%\n",
      "Log Loss: 2.580289692852738\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 57.0707%\n",
      "Log Loss: 14.827252492813216\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 97.9798%\n",
      "Log Loss: 0.9301977763139299\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 2.5253%\n",
      "Log Loss: 33.66658507180697\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"=\" * 30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    train_predictions = clf.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "5d972faa-01b5-f354-155b-9ab11cb9ab63",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Classifier Accuracy')\n",
    "plt.show()\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")\n",
    "\n",
    "plt.xlabel('Log Loss')\n",
    "plt.title('Classifier Log Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6948e0b-fa3f-151d-baf4-a5e12f6fd1ec"
   },
   "source": [
    "## Submission\n",
    "\n",
    "After choosing your favorite classifier, format the output for a leaderboard submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e8370e61-ea98-94a6-2b46-99ca7e401e9f",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearDiscriminantAnalysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f13b898b4cc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Predict Test Set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfavorite_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfavorite_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfavorite_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearDiscriminantAnalysis' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict Test Set\n",
    "favorite_clf = LinearDiscriminantAnalysis()\n",
    "favorite_clf.fit(X_train, y_train)\n",
    "test_predictions = favorite_clf.predict_proba(test)\n",
    "\n",
    "# Format DataFrame\n",
    "submission = pd.DataFrame(test_predictions, columns=classes)\n",
    "submission.insert(0, 'id', test_ids)\n",
    "submission.reset_index()\n",
    "\n",
    "# Export Submission\n",
    "from datetime import datetime\n",
    "datename = datetime.now().strftime(format = '%d%m_%H%M')\n",
    "folder = 'submissions'\n",
    "filename = folder + '/' + '10_classifiers_' + datename + '.csv'\n",
    "\n",
    "submission.to_csv(filename, index = False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 105,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
